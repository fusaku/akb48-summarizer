#!/usr/bin/env python3
"""
è½¬å½•æ¨¡å— - ä½¿ç”¨ Whisper è¿›è¡Œé«˜è´¨é‡è¯­éŸ³è½¬å½•
"""

import os
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any, Tuple
from faster_whisper import WhisperModel


class Transcriber:
    """Whisper è½¬å½•å™¨"""
    
    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ–è½¬å½•å™¨
        
        Args:
            config: é…ç½®å­—å…¸
        """
        self.config = config
        self.whisper_config = config['whisper']
        self.model = None
    
    def _load_vocabulary(self) -> str:
        """
        åŠ è½½è‡ªå®šä¹‰è¯æ±‡è¡¨
        
        Returns:
            æç¤ºæ–‡æœ¬
        """
        custom_vocab = self.whisper_config.get('custom_vocabulary', {})
        
        if not custom_vocab.get('enabled', False):
            return 'ä»¥ä¸‹ã¯æ—¥æœ¬èªã®éŸ³å£°ã§ã™ã€‚'
        
        vocab_file = custom_vocab.get('file', 'vocabulary.txt')
        
        # ç›¸å¯¹äº config/ ç›®å½•
        config_dir = Path(__file__).parent.parent / "config"
        vocab_path = config_dir / vocab_file
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(vocab_path):
            print(f"âš ï¸  è¯æ±‡è¡¨æ–‡ä»¶ä¸å­˜åœ¨: {vocab_path}")
            return 'ä»¥ä¸‹ã¯æ—¥æœ¬èªã®éŸ³å£°ã§ã™ã€‚'
        
        # è¯»å–è¯æ±‡
        try:
            with open(vocab_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            # è¿‡æ»¤ç©ºè¡Œå’Œæ³¨é‡Š
            terms = []
            for line in lines:
                line = line.strip()
                if line and not line.startswith('#'):
                    terms.append(line)
            
            if terms:
                vocab_text = 'ã€'.join(terms)
                prompt = f"ä»¥ä¸‹ã¯æ—¥æœ¬èªã®éŸ³å£°ã§ã™ã€‚\n{vocab_text}"
                print(f"âœ… åŠ è½½è‡ªå®šä¹‰è¯æ±‡è¡¨: {len(terms)} ä¸ªè¯")
                return prompt
            else:
                print(f"âš ï¸  è¯æ±‡è¡¨ä¸ºç©º")
                return 'ä»¥ä¸‹ã¯æ—¥æœ¬èªã®éŸ³å£°ã§ã™ã€‚'
                
        except Exception as e:
            print(f"âš ï¸  è¯»å–è¯æ±‡è¡¨å¤±è´¥: {e}")
            return 'ä»¥ä¸‹ã¯æ—¥æœ¬èªã®éŸ³å£°ã§ã™ã€‚'
    
    def transcribe(self, video_path: str) -> Tuple[str, List[Dict[str, Any]]]:
        """
        è½¬å½•è§†é¢‘
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            
        Returns:
            (è½¬å½•æ–‡æœ¬, ç‰‡æ®µåˆ—è¡¨)
        """
        print(f"\nğŸ“ æ­¥éª¤ 1: é«˜ç²¾åº¦è½¬å½•")
        print(f"{'='*70}")
        
        # åŠ è½½æ¨¡å‹
        if self.model is None:
            print(f"â³ åŠ è½½Whisperæ¨¡å‹: {self.whisper_config['model']}")
            print(f"   è®¾å¤‡: {self.whisper_config['device']}")
            print(f"   é‡åŒ–: {self.whisper_config['compute_type']}")
            print(f"   (é¦–æ¬¡è¿è¡Œä¼šä¸‹è½½~3GBæ¨¡å‹)\n")
            
            self.model = WhisperModel(
                self.whisper_config['model'],
                device=self.whisper_config['device'],
                compute_type=self.whisper_config['compute_type']
            )
        
        # å‡†å¤‡å‚æ•°
        quality = self.whisper_config['quality']
        vad = self.whisper_config['vad']
        
        vad_params = {
            'threshold': vad['threshold'],
            'min_silence_duration_ms': vad['min_silence_duration_ms']
        } if vad['enabled'] else None
        
        # åŠ è½½è‡ªå®šä¹‰è¯æ±‡è¡¨
        initial_prompt = self._load_vocabulary()
        
        print(f"â³ å¼€å§‹è½¬å½•ï¼ˆæœ€é«˜è´¨é‡å‚æ•°ï¼‰")
        print(f"   - beam_size: {quality.get('beam_size', 5)}")
        print(f"   - word_timestamps: å¯ç”¨")
        print(f"   - VADè¿‡æ»¤: {'å¯ç”¨' if vad['enabled'] else 'ç¦ç”¨'}")
        print(f"\n   è¯·è€å¿ƒç­‰å¾…...\n")
        
        start_time = datetime.now()
        
        # å‡†å¤‡è½¬å½•å‚æ•°
        transcribe_params = {
            'language': 'ja',
            'word_timestamps': True,
            'initial_prompt': initial_prompt,
            'beam_size': quality.get('beam_size', 5),
            'temperature': quality.get('temperature', [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]),
            'vad_filter': vad['enabled'],
        }
        
        # æ·»åŠ å¯é€‰å‚æ•°ï¼ˆå¦‚æœé…ç½®ä¸­æœ‰çš„è¯ï¼‰
        if 'best_of' in quality:
            transcribe_params['best_of'] = quality['best_of']
        if 'patience' in quality:
            transcribe_params['patience'] = quality['patience']
        if 'compression_ratio_threshold' in quality:
            transcribe_params['compression_ratio_threshold'] = quality['compression_ratio_threshold']
        if vad_params:
            transcribe_params['vad_parameters'] = vad_params
        
        # æ‰§è¡Œè½¬å½•
        segments, info = self.model.transcribe(video_path, **transcribe_params)
        
        # æ”¶é›†ç»“æœ
        transcript = ""
        segments_list = []
        
        for segment in segments:
            transcript += segment.text
            segments_list.append({
                'start': segment.start,
                'end': segment.end,
                'text': segment.text
            })
        
        elapsed = (datetime.now() - start_time).total_seconds()
        
        # æ˜¾ç¤ºç»Ÿè®¡
        print(f"âœ… è½¬å½•å®Œæˆï¼\n")
        print(f"ğŸ“Š è½¬å½•ç»Ÿè®¡:")
        print(f"   - è¯­è¨€: {info.language} (ç½®ä¿¡åº¦: {info.language_probability:.1%})")
        print(f"   - æ—¶é•¿: {info.duration:.1f}ç§’ ({info.duration/60:.1f}åˆ†é’Ÿ)")
        print(f"   - å­—ç¬¦æ•°: {len(transcript):,}")
        print(f"   - ç‰‡æ®µæ•°: {len(segments_list)}")
        print(f"   - è€—æ—¶: {elapsed:.1f}ç§’ ({elapsed/60:.1f}åˆ†é’Ÿ)")
        
        print(f"\n--- è½¬å½•é¢„è§ˆ ---")
        preview = transcript[:300] + "..." if len(transcript) > 300 else transcript
        print(preview)
        print(f"--- é¢„è§ˆç»“æŸ ---\n")
        
        return transcript, segments_list
